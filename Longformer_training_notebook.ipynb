{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2648,"status":"ok","timestamp":1674476210453,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"},"user_tz":0},"id":"yMa-OLFKidua","outputId":"e9292f7e-adfe-403a-8c6f-6dd72b0546b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25358,"status":"ok","timestamp":1674476235809,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"},"user_tz":0},"id":"zjfUfKu2JrTo","outputId":"9d808f7e-8036-45ab-bffe-391198628862"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/allenai/longformer.git\n","  Cloning https://github.com/allenai/longformer.git to /tmp/pip-req-build-alvz6yqs\n","  Running command git clone --filter=blob:none --quiet https://github.com/allenai/longformer.git /tmp/pip-req-build-alvz6yqs\n","  Resolved https://github.com/allenai/longformer.git to commit caefee668e39cacdece7dd603a0bebf24df6d8ca\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers\n","  Cloning http://github.com/ibeltagy/transformers.git (to revision longformer_encoder_decoder) to /tmp/pip-install-e_5xx_4_/transformers_e32e857f2cf645079e272adfaee11518\n","  Running command git clone --filter=blob:none --quiet http://github.com/ibeltagy/transformers.git /tmp/pip-install-e_5xx_4_/transformers_e32e857f2cf645079e272adfaee11518\n","  warning: redirecting to https://github.com/ibeltagy/transformers.git/\n","  Running command git checkout -b longformer_encoder_decoder --track origin/longformer_encoder_decoder\n","  warning: redirecting to https://github.com/ibeltagy/transformers.git/\n","  Switched to a new branch 'longformer_encoder_decoder'\n","  Branch 'longformer_encoder_decoder' set up to track remote branch 'longformer_encoder_decoder' from 'origin'.\n","  Resolved http://github.com/ibeltagy/transformers.git to commit 52d6236dc15ad5142b4146ff74d2ec973fa3da22\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning\n","  Cloning http://github.com/ibeltagy/pytorch-lightning.git (to revision v0.8.5_fixes) to /tmp/pip-install-e_5xx_4_/pytorch-lightning_3225fd018a7845d6aa4dbcaf6df0f4f2\n","  Running command git clone --filter=blob:none --quiet http://github.com/ibeltagy/pytorch-lightning.git /tmp/pip-install-e_5xx_4_/pytorch-lightning_3225fd018a7845d6aa4dbcaf6df0f4f2\n","  warning: redirecting to https://github.com/ibeltagy/pytorch-lightning.git/\n","  Running command git checkout -b v0.8.5_fixes --track origin/v0.8.5_fixes\n","  warning: redirecting to https://github.com/ibeltagy/pytorch-lightning.git/\n","  Switched to a new branch 'v0.8.5_fixes'\n","  Branch 'v0.8.5_fixes' set up to track remote branch 'v0.8.5_fixes' from 'origin'.\n","  Resolved http://github.com/ibeltagy/pytorch-lightning.git to commit 7ed5d849a0c76fa2199162f0283507e36601ded6\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from longformer==0.1) (1.13.1+cu116)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (from longformer==0.1) (2.5.1)\n","Requirement already satisfied: test-tube==0.7.5 in /usr/local/lib/python3.8/dist-packages (from longformer==0.1) (0.7.5)\n","Requirement already satisfied: nlp in /usr/local/lib/python3.8/dist-packages (from longformer==0.1) (0.4.0)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.8/dist-packages (from longformer==0.1) (0.1.2)\n","Requirement already satisfied: tensorboard>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from test-tube==0.7.5->longformer==0.1) (2.9.1)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from test-tube==0.7.5->longformer==0.1) (2.9.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from test-tube==0.7.5->longformer==0.1) (1.21.6)\n","Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.8/dist-packages (from test-tube==0.7.5->longformer==0.1) (1.3.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from test-tube==0.7.5->longformer==0.1) (0.18.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->longformer==0.1) (4.4.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from nlp->longformer==0.1) (0.3.6)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from nlp->longformer==0.1) (9.0.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from nlp->longformer==0.1) (3.2.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from nlp->longformer==0.1) (4.64.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from nlp->longformer==0.1) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from nlp->longformer==0.1) (3.9.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (6.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge_score->longformer==0.1) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge_score->longformer==0.1) (1.3.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge_score->longformer==0.1) (3.7)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->longformer==0.1) (3.19.6)\n","Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.8/dist-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.8.1rc2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2022.6.2)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.8/dist-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.1.97)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.0.53)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio>=2.3.0->test-tube==0.7.5->longformer==0.1) (7.1.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp->longformer==0.1) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp->longformer==0.1) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp->longformer==0.1) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp->longformer==0.1) (2.10)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (2.16.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.51.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.38.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score->longformer==0.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score->longformer==0.1) (1.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (3.0.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (5.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (6.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.2.2)\n"]}],"source":["!pip install git+https://github.com/allenai/longformer.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3808,"status":"ok","timestamp":1674476239604,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"},"user_tz":0},"id":"0HWslNrUJdla","outputId":"951a9620-f6f6-4d1d-e190-646733291128"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import os\n","import re\n","import random\n","import pandas as pd\n","import numpy as np\n","import csv\n","import tensorflow as tf\n","import torch\n","from google.colab import drive\n","import textwrap\n","import progressbar\n","import keras\n","from keras_preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import time\n","import datetime\n","import json\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import time\n","import datetime\n","import random\n","\n","from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig\n","import torch.nn as nn\n","import torch\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","def metrics_calculator(preds, test_labels):\n","    cm = confusion_matrix(test_labels, preds)\n","    TP = []\n","    FP = []\n","    FN = []\n","    for i in range(0,2):\n","        summ = 0\n","        for j in range(0,2):\n","            if(i!=j):\n","                summ=summ+cm[i][j]\n","\n","        FN.append(summ)\n","    for i in range(0,2):\n","        summ = 0\n","        for j in range(0,2):\n","            if(i!=j):\n","                summ=summ+cm[j][i]\n","\n","        FP.append(summ)\n","    for i in range(0,2):\n","        TP.append(cm[i][i])\n","    precision = []\n","    recall = []\n","    for i in range(0,2):\n","        precision.append(TP[i]/(TP[i] + FP[i]))\n","        recall.append(TP[i]/(TP[i] + FN[i]))\n","\n","    macro_precision = sum(precision)/2\n","    macro_recall = sum(recall)/2\n","    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n","    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n","    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n","    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n","    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4377,"status":"ok","timestamp":1674476243978,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"},"user_tz":0},"id":"OukCUqsc3V1x","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0a4fa99-9baa-4186-c088-5f6f1501dc2e"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-760f0f696c56>:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  validation_set['id'] = range(len(validation_set))\n"]}],"source":["input_file = '/content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Data/trainData/sample-train.csv'\n","#pred_file = '/content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Data/trainData/ILDC_single_dev_pred.csv'\n","\n","#save the trained model\n","output_dir     = '/content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Models/finetuned/longformer_trained_on_single_preprocessed_2_fixed/'\n","pretrained_dir = None\n","\n","\n","#test_file  = '/content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Data/trainData/ILDC_single_test_preprocessed_2.csv'\n","#pred_file  = '/content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Data/trainData/ILDC_single_test_preprocessed_2_preds.csv'\n","\n","#load data\n","df = pd.read_csv(input_file) # path to multi_dataset\n","df = df.applymap(lambda x: x.strip().replace('-\\n', '').replace('\\n', '') if isinstance(x, str) else x)\n","train_set = df.query(\" split=='train' \")\n","validation_set = df.query(\" split=='dev' \")\n","#validation_set = pd.read_csv(test_file)\n","#test_set = pd.read_csv(test_file)\n","\n","validation_set['id'] = range(len(validation_set))"]},{"cell_type":"markdown","metadata":{"id":"mV5BqP3rDVEf"},"source":["# Building the model"]},{"cell_type":"code","source":["model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', gradient_checkpointing=False, attention_window = 512)\n","#model = LongformerForSequenceClassification.from_pretrained(pretrained_dir)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cb8b71e733054b6f8011fd7911e03615","1fd9588f2b3e4a02bd48ef1e1ed848e4","36eb1572e1a148b4bd8b13b794b437c7","0399453a3eb744f89ba7789275d9b487","59a4a41f5df74d0cb77dbf2c6f232751","96b017198ec24c0b9e2c22525db6aad5","0efb8007e2a0499692c8c8a1be2c1a17","a3dc9ec0beb34f5e936db91000c4b261","40e670abc9a345dabc9cce1d895e27c5","a217ea6fa88b40acbf1c7464dbff3216","dbb73cf6fcfd498d9b60e620bfd5c4fc","bfc12734b22c4114a2379da978131d1a","5da42d13754b49298fbf367025269f34","904713a1956240e9af5f212a605f3d6b","25bfa10159aa4a1696e6990389fa25bb","56d4b57d0ffe49fe800ea097cfaa3a98","1fecdd2d9a08439c87c1c8b89726c56e","8e37764537ff4937b686e5627024100c","bc93b9f1dd95479da75d5a1d38fae293","0e1f5cbc81354660aef645f90053fbcb","d0df7fbb5ff940168cde80aa6c8bd69f","9b4d53f2ab4044148f8943b0bf714e68"]},"id":"yZsxRXDbjrXe","executionInfo":{"status":"ok","timestamp":1674476276150,"user_tz":0,"elapsed":21611,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"}},"outputId":"129cc3df-6360-4480-d7bf-b87334b2f5a3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8b71e733054b6f8011fd7911e03615"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/597M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc12734b22c4114a2379da978131d1a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["LongformerForSequenceClassification(\n","  (longformer): LongformerModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): LongformerEncoder(\n","      (layer): ModuleList(\n","        (0): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): LongformerLayer(\n","          (attention): LongformerAttention(\n","            (self): LongformerSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (query_global): Linear(in_features=768, out_features=768, bias=True)\n","              (key_global): Linear(in_features=768, out_features=768, bias=True)\n","              (value_global): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): LongformerClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"_Gr42aW0DQBe"},"source":["# Preparing data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBjxqwueJ0pq","executionInfo":{"status":"ok","timestamp":1674476323566,"user_tz":0,"elapsed":47426,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"}},"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["c9182c427dee4e8aa895bfbc354ca2f2","e2cb05a15ad3432dbe8a89b5f938e773","6225e8040dc34276b4f3d66e43465df4","34bb62aeb82249e1b956f27bbd836780","668c13b1b14e435d876d928fb2801d91","ea89a7c2b4764c539b0085691419048d","3edc6cd150bc4d63b36b2279cb98d160","29aef4b33d8b41518f3ef41ce6626ff1","46498c5aa7fb4fe9a10923d32ee5d27a","7867248d88a346fcaafce95b8354203c","63912bc8316b4a148a38db5bacdf8acc","b4fe39d9fe35442aa28a6ee46c86c99f","1d49a47d7c0d481a8186cfec82c940e1","42ec82c67fc9488c91cd25a4bca0360d","710ad9e5217d4f2e892b5b862dda65ec","edf4c902345949e6826f53576626d4dc","2246020cacba4745878c74b4db62f820","dc8d0e8375744b8698492db53b01040a","f91dafecc57a4a4eb6d7c6de5030c8b2","9c7c3b9c33454d23a3283670ebf74c8a","7b690a168ebd4ba8810ee974ef3a40d0","cfa01e4ba3724e6599c3e7a8bbec6962"]},"outputId":"b54bdf52-b9a1-4987-cca4-c5a5d32c3580"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9182c427dee4e8aa895bfbc354ca2f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4fe39d9fe35442aa28a6ee46c86c99f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100% (4982 of 4982) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n","100% (994 of 994) |######################| Elapsed Time: 0:00:07 Time:  0:00:07\n"]}],"source":["tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096')\n","\n","\n","def input_id_maker(dataf, tokenizer):\n","  input_ids = []\n","  lengths = []\n","\n","  for i in progressbar.progressbar(range(len(dataf['text']))):\n","    sen = dataf['text'].iloc[i]\n","    sen = tokenizer(sen)\n","    #CLS = tokenizer.cls_token\n","    #SEP = tokenizer.sep_token\n","    #sen = [CLS] + sen + [SEP]\n","    #encoded_sent = tokenizer.convert_tokens_to_ids(sen)\n","    input_ids.append(sen['input_ids'])\n","    lengths.append(len(sen['input_ids']))\n","\n","  input_ids = pad_sequences(input_ids, maxlen=1024, value=0, dtype=\"long\", truncating=\"pre\", padding=\"post\")\n","  return input_ids, lengths\n","\n","train_input_ids, train_lengths = input_id_maker(train_set, tokenizer)\n","validation_input_ids, validation_lengths = input_id_maker(validation_set, tokenizer)\n","\n","def att_masking(input_ids):\n","  attention_masks = []\n","  for sent in input_ids:\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    attention_masks.append(att_mask)\n","  return attention_masks\n","\n","\n","train_attention_masks = att_masking(train_input_ids)\n","validation_attention_masks = att_masking(validation_input_ids)\n","\n","train_labels = train_set['label'].to_numpy().astype('int')\n","validation_labels = validation_set['label'].to_numpy().astype('int')\n","#validation_labels = validation_set['id'].to_numpy().astype('int')\n","\n","train_inputs = train_input_ids\n","validation_inputs = validation_input_ids\n","train_masks = train_attention_masks\n","validation_masks = validation_attention_masks\n","\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","\n","# max batch size should be 6 due to colab limits\n","batch_size = 6\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqBkaIbDKMlX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_rrz5-vKX_x"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDFGL8XPKZ86"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1UJt0WJKfAR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgyK6Q5vKiX8"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"hkh-Hia2f2n7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OzM0B_2KQUmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Brjk4PmV4EEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation of the pretrained model on training set before fine-tuning "],"metadata":{"id":"cudbvjw64EM1"}},{"cell_type":"code","source":["'''batch_size = 6\n","prediction_data = TensorDataset(train_inputs, train_masks, train_labels)\n","prediction_sampler = SequentialSampler(train_data)\n","prediction_dataloader = DataLoader(train_data, shuffle=False, sampler=None, batch_size = batch_size)\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_data)))\n","model.eval()\n","predictions , true_labels = [], []\n","explanations = []\n","for (step, batch) in enumerate(prediction_dataloader):\n","  batch = tuple(t.to(device) for t in batch)  \n","  b_input_ids, b_input_mask, b_labels = batch\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      logits= outputs[0]\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)\n","pred_flat = np.argmax(predictions, axis=1).flatten()\n","labels_flat = true_labels.flatten()\n","print(flat_accuracy(predictions,true_labels))\n","macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n","print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)\n","print('    DONE.')\n","print(predictions)'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"q8Oua0yLP9XB","executionInfo":{"status":"ok","timestamp":1674476323570,"user_tz":0,"elapsed":20,"user":{"displayName":"Thanet Markchom","userId":"13676560265965962179"}},"outputId":"39115a17-f18a-46da-ff35-7a209c555774"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"batch_size = 6\\nprediction_data = TensorDataset(train_inputs, train_masks, train_labels)\\nprediction_sampler = SequentialSampler(train_data)\\nprediction_dataloader = DataLoader(train_data, shuffle=False, sampler=None, batch_size = batch_size)\\nprint('Predicting labels for {:,} test sentences...'.format(len(prediction_data)))\\nmodel.eval()\\npredictions , true_labels = [], []\\nexplanations = []\\nfor (step, batch) in enumerate(prediction_dataloader):\\n  batch = tuple(t.to(device) for t in batch)  \\n  b_input_ids, b_input_mask, b_labels = batch\\n  with torch.no_grad():\\n      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\\n      logits= outputs[0]\\n  logits = logits.detach().cpu().numpy()\\n  label_ids = b_labels.to('cpu').numpy()\\n  predictions.append(logits)\\n  true_labels.append(label_ids)\\npredictions = np.concatenate(predictions, axis=0)\\ntrue_labels = np.concatenate(true_labels, axis=0)\\npred_flat = np.argmax(predictions, axis=1).flatten()\\nlabels_flat = true_labels.flatten()\\nprint(flat_accuracy(predictions,true_labels))\\nmacro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\\nprint(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)\\nprint('    DONE.')\\nprint(predictions)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"JhOxyACHTs-h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R1-7D6UxDKPv"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nyr_rKJDKqX1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b295e25f-318c-4c13-c1bd-e1e410805c79"},"outputs":[{"output_type":"stream","name":"stdout","text":["======== Epoch 1 / 10 ========\n","Training...\n","  Batch    40  of    831. \n","  Batch    80  of    831. \n","  Batch   120  of    831. \n","  Batch   160  of    831. \n","  Batch   200  of    831. \n","  Batch   240  of    831. \n","  Batch   280  of    831. \n","  Batch   320  of    831. \n","  Batch   360  of    831. \n","  Batch   400  of    831. \n","  Batch   440  of    831. \n","  Batch   480  of    831. \n","  Batch   520  of    831. \n","  Batch   560  of    831. \n","  Batch   600  of    831. \n","  Batch   640  of    831. \n","  Batch   680  of    831. \n","  Batch   720  of    831. \n","  Batch   760  of    831. \n","  Batch   800  of    831. \n","\n","  Average training loss: 0.68\n","  Saving model to /content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Models/finetuned/longformer_trained_on_single_preprocessed_2_fixed/ (epoch 0)\n","======== Epoch 2 / 10 ========\n","Training...\n","  Batch    40  of    831. \n","  Batch    80  of    831. \n","  Batch   120  of    831. \n","  Batch   160  of    831. \n","  Batch   200  of    831. \n","  Batch   240  of    831. \n","  Batch   280  of    831. \n","  Batch   320  of    831. \n","  Batch   360  of    831. \n","  Batch   400  of    831. \n","  Batch   440  of    831. \n","  Batch   480  of    831. \n","  Batch   520  of    831. \n","  Batch   560  of    831. \n","  Batch   600  of    831. \n","  Batch   640  of    831. \n","  Batch   680  of    831. \n","  Batch   720  of    831. \n","  Batch   760  of    831. \n","  Batch   800  of    831. \n","\n","  Average training loss: 0.67\n","  Saving model to /content/drive/MyDrive/Colab Notebooks/SemEval2023/CJPE-main/Models/finetuned/longformer_trained_on_single_preprocessed_2_fixed/ (epoch 1)\n","======== Epoch 3 / 10 ========\n","Training...\n","  Batch    40  of    831. \n","  Batch    80  of    831. \n","  Batch   120  of    831. \n","  Batch   160  of    831. \n","  Batch   200  of    831. \n","  Batch   240  of    831. \n","  Batch   280  of    831. \n","  Batch   320  of    831. \n","  Batch   360  of    831. \n","  Batch   400  of    831. \n","  Batch   440  of    831. \n","  Batch   480  of    831. \n","  Batch   520  of    831. \n","  Batch   560  of    831. \n","  Batch   600  of    831. \n","  Batch   640  of    831. \n"]}],"source":["lr = 2e-6\n","max_grad_norm = 1.0\n","epochs = 10\n","num_total_steps = len(train_dataloader)*epochs\n","num_warmup_steps = 1000\n","warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n","optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_total_steps)\n","seed_val = 2212\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","    total_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","        if step % 40 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}. '.format(step, len(train_dataloader)))\n","\n","        \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        \n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","    # Create output directory if needed\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    print(\"  Saving model to %s (epoch %d)\" % (output_dir,epoch_i))\n","\n","    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","    # They can then be reloaded using `from_pretrained()`\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","    model_to_save.save_pretrained(output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","\n","\n","    if (epoch_i+1)%5 == 0:\n","        \n","      print(\"\")\n","      print(\"Running Validation...\")\n","\n","      t0 = time.time()\n","\n","      model.eval()\n","\n","      eval_loss, eval_accuracy = 0, 0\n","      nb_eval_steps, nb_eval_examples = 0, 0\n","\n","      for batch in validation_dataloader:\n","          batch = tuple(t.to(device) for t in batch)\n","          b_input_ids, b_input_mask, b_labels = batch\n","          \n","          with torch.no_grad():        \n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      \n","          logits = outputs[0]\n","\n","          logits = logits.detach().cpu().numpy()\n","          label_ids = b_labels.to('cpu').numpy()\n","          \n","          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","          eval_accuracy += tmp_eval_accuracy\n","\n","          nb_eval_steps += 1\n","\n","      # Report the final accuracy for this validation run.\n","      print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","source":[],"metadata":{"id":"dUY75hkl3BXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9tRZMes89_ky"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZL4jYL_vDEej"},"source":["#Predicting"]},{"cell_type":"code","source":[],"metadata":{"id":"S2gXOSxH3CWF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1-nrvVp0o7fy"},"source":["## Evaluation on training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCOktf8SDb5L"},"outputs":[],"source":["batch_size = 6\n","\n","prediction_data = TensorDataset(train_inputs, train_masks, train_labels)\n","prediction_sampler = SequentialSampler(train_data)\n","prediction_dataloader = DataLoader(train_data, shuffle=False, sampler=None, batch_size = batch_size)\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_data)))\n","model.eval()\n","\n","predictions , true_labels = [], []\n","explanations = []\n","\n","for (step, batch) in enumerate(prediction_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  b_input_ids, b_input_mask, b_labels = batch\n","  #print(b_input_ids)\n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","      #print(outputs)\n","      logits= outputs[0]\n","      #attentions = outputs.attentions[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  #attentions = attentions.detach().cpu().numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)\n","pred_flat = np.argmax(predictions, axis=1).flatten()\n","labels_flat = true_labels.flatten()\n","\n","print(flat_accuracy(predictions,true_labels))\n","\n","macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n","print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)\n","\n","print('    DONE.')"]},{"cell_type":"markdown","source":["**Original** \n","\n","3 epochs\n","Predicting labels for 4,982 test sentences...\n","0.8855881172219991\n","0.8914680269703594 0.8649874107904924 0.878028105779464 \n","0.8855881172219991 0.8855881172219991 0.8855881172219991\n","\n","\n","10 epochs\n","Predicting labels for 4,982 test sentences...\n","0.9353673223604978\n","0.939945656855312 0.9231056446561747 0.9314495428110406 0.9353673223604978 0.9353673223604978 0.9353673223604978\n","\n","\n","**Preprocessed_2**\n","\n","10 epochs \n","Predicting labels for 4,982 test sentences...\n","0.9283420313127259\n","0.9358543523405729 0.9129802171516941 0.924275783156626 0.9283420313127259 0.9283420313127259 0.9283420313127259"],"metadata":{"id":"s1aWP11tHwvn"}},{"cell_type":"markdown","metadata":{"id":"_oWVq6yHo_nC"},"source":["##Evaluation on dev set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nn0CrsHYM9fz"},"outputs":[],"source":["batch_size = 6\n","\n","prediction_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","prediction_sampler = SequentialSampler(validation_data)\n","prediction_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_data)))\n","model.eval()\n","\n","predictions , true_labels = [], []\n","explanations = []\n","\n","for (step, batch) in enumerate(prediction_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  b_input_ids, b_input_mask, b_labels = batch\n","  #print(b_input_ids)\n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","      #print(outputs)\n","      logits= outputs[0]\n","      #attentions = outputs.attentions[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  #attentions = attentions.detach().cpu().numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)\n","pred_flat = np.argmax(predictions, axis=1).flatten()\n","labels_flat = true_labels.flatten()\n","\n","print(flat_accuracy(predictions,true_labels))\n","\n","macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n","print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)\n","\n","print('    DONE.')"]},{"cell_type":"markdown","source":["**Original**\n","\n","3 epochs\n","Predicting labels for 994 test sentences...\n","0.5925553319919518\n","0.7062463914549654 0.5925553319919517 0.6444248685566497 \n","0.5925553319919518 0.5925553319919518 0.5925553319919518\n","\n","\n","10 epochs \n","Predicting labels for 994 test sentences...\n","0.6247484909456741\n","0.6833642768732744 0.624748490945674 0.6527431139665323 0.6247484909456741 0.6247484909456741 0.6247484909456741\n","\n","**preprocessed_2**\n","\n","10epochs \n","Predicting labels for 994 test sentences...\n","0.6187122736418511\n","0.6935153898949369 0.6187122736418511 0.6539817679670216 0.6187122736418511 0.6187122736418511 0.6187122736418511"],"metadata":{"id":"DOv7qfWfHz16"}},{"cell_type":"markdown","source":["#Predict testset"],"metadata":{"id":"J1CqyOjXiYHs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAdWPBXvwydo"},"outputs":[],"source":["'''batch_size = 1\n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, shuffle=False, sampler=None, batch_size = batch_size)\n","assert len(prediction_data) == 1500\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_data)))\n","model.eval()\n","\n","predictions , true_labels = [], []\n","explanations = []\n","\n","for (step, batch) in enumerate(prediction_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  b_input_ids, b_input_mask, b_labels = batch\n","  #print(b_input_ids)\n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","      logits = outputs[0]\n","      \n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)\n","pred_flat = np.argmax(predictions, axis=1).flatten()\n","labels_flat = true_labels.flatten()\n","\n","\n","print('    DONE.')\n","\n","validation_set['id2'] = labels_flat\n","validation_set['prediction'] = pred_flat\n","assert all(validation_set['id2'] == validation_set['id'])\n","validation_set.to_csv(pred_file, index=False,)'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"By4GNgg1_k1Q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQbvOT4kkPxz"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cb8b71e733054b6f8011fd7911e03615":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fd9588f2b3e4a02bd48ef1e1ed848e4","IPY_MODEL_36eb1572e1a148b4bd8b13b794b437c7","IPY_MODEL_0399453a3eb744f89ba7789275d9b487"],"layout":"IPY_MODEL_59a4a41f5df74d0cb77dbf2c6f232751"}},"1fd9588f2b3e4a02bd48ef1e1ed848e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96b017198ec24c0b9e2c22525db6aad5","placeholder":"​","style":"IPY_MODEL_0efb8007e2a0499692c8c8a1be2c1a17","value":"Downloading: 100%"}},"36eb1572e1a148b4bd8b13b794b437c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3dc9ec0beb34f5e936db91000c4b261","max":694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40e670abc9a345dabc9cce1d895e27c5","value":694}},"0399453a3eb744f89ba7789275d9b487":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a217ea6fa88b40acbf1c7464dbff3216","placeholder":"​","style":"IPY_MODEL_dbb73cf6fcfd498d9b60e620bfd5c4fc","value":" 694/694 [00:00&lt;00:00, 13.3kB/s]"}},"59a4a41f5df74d0cb77dbf2c6f232751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96b017198ec24c0b9e2c22525db6aad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efb8007e2a0499692c8c8a1be2c1a17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3dc9ec0beb34f5e936db91000c4b261":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40e670abc9a345dabc9cce1d895e27c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a217ea6fa88b40acbf1c7464dbff3216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbb73cf6fcfd498d9b60e620bfd5c4fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc12734b22c4114a2379da978131d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5da42d13754b49298fbf367025269f34","IPY_MODEL_904713a1956240e9af5f212a605f3d6b","IPY_MODEL_25bfa10159aa4a1696e6990389fa25bb"],"layout":"IPY_MODEL_56d4b57d0ffe49fe800ea097cfaa3a98"}},"5da42d13754b49298fbf367025269f34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fecdd2d9a08439c87c1c8b89726c56e","placeholder":"​","style":"IPY_MODEL_8e37764537ff4937b686e5627024100c","value":"Downloading: 100%"}},"904713a1956240e9af5f212a605f3d6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc93b9f1dd95479da75d5a1d38fae293","max":597257159,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e1f5cbc81354660aef645f90053fbcb","value":597257159}},"25bfa10159aa4a1696e6990389fa25bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0df7fbb5ff940168cde80aa6c8bd69f","placeholder":"​","style":"IPY_MODEL_9b4d53f2ab4044148f8943b0bf714e68","value":" 597M/597M [00:09&lt;00:00, 81.8MB/s]"}},"56d4b57d0ffe49fe800ea097cfaa3a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fecdd2d9a08439c87c1c8b89726c56e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e37764537ff4937b686e5627024100c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc93b9f1dd95479da75d5a1d38fae293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e1f5cbc81354660aef645f90053fbcb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0df7fbb5ff940168cde80aa6c8bd69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b4d53f2ab4044148f8943b0bf714e68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9182c427dee4e8aa895bfbc354ca2f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2cb05a15ad3432dbe8a89b5f938e773","IPY_MODEL_6225e8040dc34276b4f3d66e43465df4","IPY_MODEL_34bb62aeb82249e1b956f27bbd836780"],"layout":"IPY_MODEL_668c13b1b14e435d876d928fb2801d91"}},"e2cb05a15ad3432dbe8a89b5f938e773":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea89a7c2b4764c539b0085691419048d","placeholder":"​","style":"IPY_MODEL_3edc6cd150bc4d63b36b2279cb98d160","value":"Downloading: 100%"}},"6225e8040dc34276b4f3d66e43465df4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29aef4b33d8b41518f3ef41ce6626ff1","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46498c5aa7fb4fe9a10923d32ee5d27a","value":898823}},"34bb62aeb82249e1b956f27bbd836780":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7867248d88a346fcaafce95b8354203c","placeholder":"​","style":"IPY_MODEL_63912bc8316b4a148a38db5bacdf8acc","value":" 899k/899k [00:01&lt;00:00, 740kB/s]"}},"668c13b1b14e435d876d928fb2801d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea89a7c2b4764c539b0085691419048d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3edc6cd150bc4d63b36b2279cb98d160":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29aef4b33d8b41518f3ef41ce6626ff1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46498c5aa7fb4fe9a10923d32ee5d27a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7867248d88a346fcaafce95b8354203c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63912bc8316b4a148a38db5bacdf8acc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4fe39d9fe35442aa28a6ee46c86c99f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d49a47d7c0d481a8186cfec82c940e1","IPY_MODEL_42ec82c67fc9488c91cd25a4bca0360d","IPY_MODEL_710ad9e5217d4f2e892b5b862dda65ec"],"layout":"IPY_MODEL_edf4c902345949e6826f53576626d4dc"}},"1d49a47d7c0d481a8186cfec82c940e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2246020cacba4745878c74b4db62f820","placeholder":"​","style":"IPY_MODEL_dc8d0e8375744b8698492db53b01040a","value":"Downloading: 100%"}},"42ec82c67fc9488c91cd25a4bca0360d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f91dafecc57a4a4eb6d7c6de5030c8b2","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c7c3b9c33454d23a3283670ebf74c8a","value":456318}},"710ad9e5217d4f2e892b5b862dda65ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b690a168ebd4ba8810ee974ef3a40d0","placeholder":"​","style":"IPY_MODEL_cfa01e4ba3724e6599c3e7a8bbec6962","value":" 456k/456k [00:00&lt;00:00, 394kB/s]"}},"edf4c902345949e6826f53576626d4dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2246020cacba4745878c74b4db62f820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc8d0e8375744b8698492db53b01040a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f91dafecc57a4a4eb6d7c6de5030c8b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c7c3b9c33454d23a3283670ebf74c8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b690a168ebd4ba8810ee974ef3a40d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfa01e4ba3724e6599c3e7a8bbec6962":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}